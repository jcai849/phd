\documentclass[a4paper,10pt]{article}

\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{biblatex}
\addbibresource{../bib/bibliography.bib}

\begin{document}
\title{A Survey of Large-Scale Platform Features}
\author{Jason Cairns}
\year=2020 \month=4 \day=16
\maketitle

\section{Introduction}\label{sec:intro}

To guide the development of the platform, desirable features are drawn from
existing platforms; inferred as logical extensions; and arrived at through
identification of needs. Some features are mutually exclusive, others are
suggestive of each other, but are worth considering and contrasting their
merits.

\section{Feature List}\label{sec:feature-list}

A list of features and their descriptions follows:

\begin{description}
	\item[Distributed Functionality]
	      The ability to spread computation and data over separate
	      computers.
	      The value of distributed computing is well recognised for
	      large-scale computing, in the increased capacity for
	      processing, memory, and storage.
	      Distributed computing typically gains latency speedup through
	      parallel processing; both Amdahl's law and Gustafson's law give
	      theoretical speedups for parallel jobs \cite{amdahl1967law}
	      \cite{gustafson1988law}.
	      In addition, each node typically adds more working memory to
	      the distributed system, allowing for larger datasets to be
	      manipulated in-memory.
	      For exceedingly large datasets, the benefits of distributed
	      file systems commonly allow for resiliant storage, with
	      well-regarded examples including HDFS and the Google File
	      System it is based upon \cite{shvachko2010hadoop}
	      \cite{ghemawat2003google}.
	\item[Arbitrary Code Evaluation]
	      The ability to make use of user-specified code in processing.
	      Most R packages for large-scale computing do enable arbitrary
	      code, however they typically have some limitations, such as an
	      inability to recognise global variables, as is the case with
	      sparklyr and to a lesser extent future
	      \cite{sparklyr2020limitations} \cite{microsoft20}.
	      The ability for a system to adhere to a similar interface
	      despite changes in internal behaviour is useful for the sake of
	      referential transparency, as well as human-computer interaction
	      considerations \cite{sondergaard1990Rtda}
	      \cite{norman2013design}.
	      For example, the foreach package can change parallel adaptors in
		a single line of setup, without needing any changes made in the
		code referencing future, despite making use of a different internal
		interface \cite{weston19:_using}
	\item[Arbitrary Iterative Code Evaluation]
	      The ability to process user-specified code involving iteration
	      over the whole dataset, as opposed to a simple mapping.
	      This reflects the inherently iterative nature of many
	      statistical algorithms.
	      Furthermore, this shouldn't initiate a new job or process for
	      every new iteration.
	      This is seen as important enough that it serves as a major
		motivating factor behind Spark's development, overcoming a
		perceived major deficiency of Hadoop by Spark's developers
		\cite{zaharia2010spark}.
	\item[Object Persistence at Nodes]
	      The ability to retain objects in-memory at their point of
	      processing.
	      The standard motivation for such a feature revolves around a
	      reduction in data movement, which serves to slow down
	      processing enormously through forcing programs to be I/O bound.
	      In-memory persistence is closely related to the capacity for
	      iterative code evaluation in a distributed system, and was
	      similarly referenced by the Spark developers as an
	      apparent benefit of Spark\cite{zaharia2010spark}.
	\item[Support for HDFS]
	      Capacity to work with data and computation on the Hadoop
	      Distributed File System (HDFS).
	      As a well-established distributed file system, HDFS is targeted
	      by a number of R packages, as well as serving as a file
	      system base for other platforms such as spark
	      \cite{analytics:_rhadoop_wiki} \cite{deltarho:_rhipe}
	      \cite{urbanek20} \cite{zaharia2016apache}.
	      HDFS offers several features that make it particularly
	      attractive as a filesystem for a large-scale statistical
	      analysis;
	      being distributed and capable of running on commodity hardware
	      allows for truly big data analysis.
	      In addition, the system is built to be resiliant to hardware
	      failure, so long-running analyses aren't cut short or forced to
	      revert to a checkpoint because of singular component failure
	      \cite{shvachko2010hadoop}.
	\item[Ease of Setup]
	      Is setup suitable for a computationally-focussed
	      statistician, or does it require a system administrator?
	      At it's base, R is a statistical programming language
	      \cite{rcore2020intro}.
	      The particular skills of statisticians seldom correspond to the
	      those requisite of system administration, with such a focus
	      unlikely to compete successfully with their main research.
	      Ease of deployment can determine a platform's success, with
	      such a feature being one of the many motivations for the use
	      and development of tools such as docker in recent years.
	      %% lapack setup difficult (example) - quick installation guide (25 pages)
	\item[Inter-Node Communication]
	      Can any pair of nodes communicate with each other, or do they
	      only report to a master node?
	      While many tasks process efficiently within a standard
	      master-slave architecture, and inter-node communication is
	      inherently expensive, there is still a large class of tasks
	      that benefit from inter-node communication\cite{walker1996mpi};
	      particularly graph-based statistical methods.
	\item[Interactive Usage]
	      The ability to make use of the package in an interactive R
	      session, without mandatory batch execution.
	      A major benefit of R as being interpreted is the availability
	      of the REPL. The benefits of interactivity stemming from a REPL
	      are well-documented, most notably aiding debugging
	      \cite{mccarthy1978history}. For statistical analysese in 
	      particular, interactive analyses play a major role in 
	      exploratory data analysis, wherein insights can be tested
	      and arrived at rapidly with an interactive session.
	\item[Backend Decoupling]
	      The implementation is maintained entirely separately to the
	      interface.
	      This is standard in most of the performant parallel R systems
	      as described by \cite{eddelbuettel2019parallel}, including
	      \cite{microsoft20} as a key example.
	      As a software pattern, this is a case of separation of
	      concerns, described in detail by \cite{dijkstra1982role}.
	      Such a pattern fosters modularity and allows for a broader
	      range of backends to be made use of, maximising the uptake of
	      the platform.
	\item[Evaluation of Arbitrary Classes]
	      Any class, including user-defined classes, can be used in
	      evaluation.
	      There is proven value in rich user-defined objects, with the
	      weight of much of the object-oriented programming paradigm
	      serving to further that point \cite{dahl2004simula}.
	      Conversely, many major packages limit themselves through
	      provisioning only a few classes, such as pbdDMAT with
	      distributed matrices, or the tidyverse and it's derivatives
	      including sparklyr with ``tibbles'' \cite{pbdDMATpackage}
	      \cite{wickham2019welcome}
	\item[Direct API]
	      The platform is explicitly programmed against at a
	      platform-specific, mostly monomorphic interface. 
	      This is in contrast with packages providing methods which
	      overload standard generics or language structure;
	      at a loss of general transparency, direct API's can ensure
	      greater encapsulation and a closer mapping of code with the
	      underlying implementation, thus potentially resulting in
	      performance gains \cite{bierhoff2009api}.
	      An example in R is the interface to the foreach package not
	      overloading the existing for-loop syntax in R, but defining it's
	      own specific interface \cite{microsoft20}. 
      \item[Class for Generics]
	      The platform is programmed against using a polymorphic interface,
	      with the package methods taking advantage of standard generics.
	      This is in contrast with a direct API, though it is not entirely
	      mutually exclusive;
	      methods can be defined alongside package classes, which overload
	      generics such that programming with the package is nearly
	      entirely equivalent to programming with standard R objects,
	      though a further API can be made available.
	      pbdDMAT takes this approach, as well as
	      bigmemory\cite{pbdDMATpackage}\cite{kane13:bigmemory}.
	\item[dplyr Compatible]
	      The platform makes use of dplyr as the standard generics to
	      implicitly program over.
	      Using a dplyr interface is a common trend in several R packages
	      including sparklyr, disk.frame, and many database interfaces
	      \cite{luraschi20}\cite{zj20}.
	      Such an interface is claimed by the dplyr creators to aid
	      beginners through being simple to remember \cite{wickham2019welcome}.
	      In this way, it may serve to ease the learning curve for the platform.
	      %% ubiquity of dplyr (try put in something about Rstudio being the 
	      %% Red Hat of R, and dplyr being often redundant to things there 
	      %% before as well as their non-acknowledgement of everything prior 
	      %% (that typically do things better and faster), almost at a level of 
	      %% plaigiarism
\end{description}

\section{Comparison Table}\label{sec:comp-tab}

\begin{table}[h!]
	\begin{tabular}{@{}llllll@{}}
		\toprule
		\multicolumn{1}{c}{Feature}         & \multicolumn{4}{c}{Platform} &                                        \\ \midrule
		                                    & RHadoop                      & Sparklyr & pbdR & disk.frame & foreach \\ \cmidrule(l){2-6}
		Distributed Functionality           &                              &          &      &            &         \\
		Arbitrary Code Evaluation           &                              &          &      &            &         \\
		Arbitrary Iterative Code Evaluation &                              &          &      &            &         \\
		Object Persistence at Nodes         &                              &          &      &            &         \\
		Support for HDFS                    &                              &          &      &            &         \\
		Ease of Setup                       &                              &          &      &            &         \\
		Inter-Node Communication            &                              &          &      &            &         \\
		Interactive Usage                   &                              &          &      &            &         \\
		Backend Decoupling                  &                              &          &      &            &         \\
		Evaluation of Arbitrary Classes     &                              &          &      &            &         \\
		Direct API                          &                              &          &      &            &         \\
		Class for Generics                  &                              &          &      &            &         \\
		dplyr Compatible                    &                              &          &      &            &         \\ \bottomrule
	\end{tabular}
	\caption{Comparison of major features among platforms\label{tab:compare-features}}
\end{table}

\printbibliography{}
\end{document}
