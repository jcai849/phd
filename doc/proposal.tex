\documentclass[a4paper,10pt]{article}
\usepackage{doc/header}

\begin{document}

\begin{titlepage}
\begin{center}
	\vskip1cm
  \bfseries
  \huge UNIVERSITY OF AUCKLAND
  \vskip0.8cm
  {\LARGE Faculty of Science}
  \vskip0.5cm
  \large Department of Statistics
  \vskip1.5cm
  \Large Doctoral Research Proposal
  \vskip4cm
  \emph{\huge A Platform for Large-Scale Statistical Modelling Using R}
\end{center}

\vskip6cm

\begin{minipage}{.4\textwidth}
  \begin{flushleft}
	  \bfseries\large Supervisors:\par \emph{Dr. Simon Urbanek}\par \emph{Dr. Paul Murrell}

  \end{flushleft}
\end{minipage}
\hskip.3\textwidth
\begin{minipage}{.3\textwidth}
  \begin{flushleft}
    \bfseries\large Student:\par \emph{Jason Cairns}
  \end{flushleft}
\end{minipage}

\vskip2cm

\centering
\bfseries
\Large 2021-XX-XX
\end{titlepage}

\tableofcontents
\newpage
\section{Introduction}

Statistics is concerned with the analysis of datasets, which are continually growing bigger, and at a faster rate;
the global datasphere is expected to grow from 33 zettabytes in 2018 to 175 zettabytes by 2025\cite{rydning2018digitization}.
The scale of this growth is staggering, and continues to outpace attempts to engage meaningfully with such large datasets. 

By one measure, information storage capacity has grown at a compound annual rate of 23\% per capita over recent decades\cite{hilbert2011world}.
In spite of such massive growths in storage capacity, they are far outstripped by computational capacity over time \cite{fontana2018moore}.
Specifically, the number of components comprising an integrated circuit for computer processing have been exponentially increasing, with an additional exponential decrease in their cost\cite{moore1975progress}.
This observation, known as Moore's Law, has been the root cause for much of computational advancement over the past half-century.
The corresponding law for computer storage posits increase in bit density of storage media along with corresponding decreases in price, which has been found to track lower than expected by Moore's law metrics.
Such differentials between the generation of data, computational capacity for data processing, and constraints on data storage, have forced new techniques in computing for the analysis of large-scale data.\\

The statistician working with large datasets is constrained by the forces of increased memory and processing power, along the more overwhelming force of increased dataset size.
To take a concrete example of the problem, consider how a statistician may attempt to fit a novel model for a dataset consisting of roughly 165 million flight datapoints\cite{bot2009flights}, using methods and computational facilities typical to a small dataset.
This is actually a small dataset compared to many other large datasets, yet it is still not possible to perform an analysis in the same manner as would usually be conducted on small-scale datasets.
\texttt{R}, or any other common statistical computing system, simply won't be able to read in the data in the same fashion, as it is too big to fit in memory.
The reason for this failure lies in the memory hierarchy of computers, wherein the different forms of data storage utilised by computers have varying response times and volatility.
Using the Dell Optiplex 5080 as a typical desktop PC build, the statistician has 16Gb of Random Access Memory (RAM) for fast main memory, to be used as a program data store; and a 256Gb Solid State Drive (SSD) for slow long-term disk storage\cite{cornell2021standardcomp}.
The problem can be summed up in the need for handling datasets that are too large to fit in memory.

As a major and growing issue, there have been a plethora of responses over decades, and will be described in further detail in section \ref{background} below.  
None of the responses are entirely satisfactory for the working statistician, who may be reasonably posited to possess the following demands:

\begin{itemize}
	\item A platform that can enable the creation of novel models and apply them to larger-than-memory datasets.
	\item This platform must allow interactivity.
	\item It must be simple to use and easy to set up.
		Ideally, as close to existing systems as possible.
	\item It must be fast.
	\item It must take advantage of existing large ecosystems of statistical software.
	\item It must be robust.
	\item It must be flexible and extensible.
		A computational statistician may create custom classes and reasonably expect them to work well with the platform.
\end{itemize}

To this end, the use of the \texttt{R} programming language is a natural starting point.
The means for writing software is typically through the use of a structured, high-level programming language.
Of the myriad programming languages available, the most widespread language used for statistics is R.
In August 2020, \texttt{R} reached it's highest rank yet of 8th in the TIOBE index, a ranking of most popular programming languages, up from ranking 73rd in December 2008\cite{tiobe2021r}.
R also has a special relevance for this proposal, having been initially developed at the University of Auckland by Ross Ihaka and Robert Gentleman in 1991\cite{ihaka1996r}.

Major developments in contemporary statistical computing are typically published alongside R code implementation, usually in the form of an R package, which is a mechanism for extending R and sharing functions.
As of March 2021, the Comprehensive R Archive Network (CRAN) hosts over 17000 available packages\cite{team20:_r}.

This project seeks to build and document the statistician's large-scale modelling platform in \texttt{R}.
Preliminary results have been extremely encouraging to this endeavour, and are described in more detail in section \ref{curr} below.
There remains plenty of future work, and this is described in section \ref{future}, with tangible goals outlined in section \ref{goals}.

\section{Background}\label{background}

% Completely redo - structure by different approaches, and what packages/systems do these
\input{doc/proposal/background}

\section{Methodology and Approach}

The principal methodology is to utilise a research software development approach, informed by statistical ends.
This includes experimental research and rapid prototyping, along with open-source practices for public feedback.
Constraints of such an approach include the many software development practices being intended primarily for teams of software developers, which is not the case in this project, as well as the need to engage in marketing in order to have any broad feedback on an open-source project.
An immediate technical challenge that exists is the staggering array of potential technologies that could be used, coupled with the myriad niche demands of end users sitting at varying stages of their respective technologies' hype cycles.
This is typically overcome through experience but failing that, an emphasis on communication and high levels of background research can be used to manage such an uncertainty.
The central use of R also presents it's own challenges, but these are often surmounted through a foreign language interface, such as C.

Further work will continue from the existing prototype, which is described in turn in section \ref{curr} below.
Progress on written PhD work and experimentation is freely accessible from the \href{https://github.com/jcai849/phd}{jcai849/phd} GitHub repository, and work on the LargeScaleR package is available from the \href{https://github.com/jcai849/phd}{jcai849/largeScaleR} GitHub repository. 

\section{Preliminary Results}\label{curr}

% change master-worker, and stub terminology
% diagrams useful
\input{doc/proposal/curr}

\section{Future Work}\label{future}

%\input future work

\section{Objectives \& Goals}\ref{goals}

The objective of this research project is to create a platfom for large-scale statistical computing, utilising the versatility and power of R.
Such a platform will allow statisticians to easily define and run complex distributed algorithms from within the R environment, rather than having to rely on external tools that never had statistical computation as a goal.
This platform will be demonstrated through the implementation of iterative models in R, and applying these models to real-world tasks on large-scale problems.

The following tasks will be undertaken as a part of the proposed research:

\begin{enumerate}
	\item Development of further proposed platform features, including:
		\begin{enumerate}
			\item Efficient memory usage through transient data and command chaining
			\item Fault Tolerance
			\item Interfaces with external systems
		\end{enumerate}
	\item The demonstration of such a platform through implementing complex iterative statistical models on larger-than-memory datasets
	\item Publishing the LargeScaleR package on CRAN. This requires additional development including:
		\begin{enumerate}
			\item Stability as may be expected from 90+\% test coverage
			\item Full documentation for all base functions
			\item A package vignette
			\item Passing CRAN checks
		\end{enumerate}
	\item Publishing a technical report on XXX
	\item Presenting on the platform at XXX
	\item Benchmarking the platform on real-world data at a scale of 64+ nodes and 100Gb+ data source size
\end{enumerate}

\section{TODO Deliverables and Program Schedule}

All provisional goals have been completed, with the goal of proposal approval being contingent on the committee.
A description of the goals and statements on their completion follows:

\begin{enumerate}
	\item Approval of the full thesis proposal by the appropriate departmental/faculty postgraduate committee.
		This will be granted contingent on the reception of this proposal.
	\item A substantial piece of written work, such as a literature review, completed to the satisfaction of the main supervisor.
		A 15,000 word literature review document has been produced, at a draft stage that is completed to the satisfaction of the main supervisor. 
		This can be found in the \texttt{phd} git repository under \texttt{doc/lit-review.tex}.
	\item Ethics approval/s and/or permissions obtained for the research (if required). 
		No ethics approval or permissions are required
	\item Attendance at one of the Doctoral Skills Programme Induction Days.
		This was completed on 2020-05-29.
	\item Successful completion of the Academic Integrity Module.
		This was completed during undergraduate study.
	\item A needs analysis to determine training and other requirements that must be completed before candidature can be confirmed.
		This was completed, with the document presented to the PYR committee.
	\item Completion of a health and safety risk assessment and training for any laboratory/studio/field and related work activities.
		No health and safety training was required for the type of work needed for this project.
	\item Undertake Diagnostic English Language Needs Assessment (DELNA) online screening. 
		If a full assessment is advised, complete full diagnostic test and participate in any language enrichment recommended by the DELNA Language Advisor.
		This was completed during undergraduate study.
	\item Write a review of existing methods and literature on approaches to distributed computing with R and current solutions in other language/systems with similar goals for statistical modelling like Python or Spark, to the satisfaction of the primary supervisor. 
		This was completed and can be found in the \texttt{phd} git repository under \texttt{doc/survey*}.
	\item Implement a prototype R software capable of performing operations on multiple chunks of data in parallel on different machines and use the prototype to implement one statistical model, to the satisfaction of the primary supervisor.
		This has been satisfied through the development of the \textbf{largeScaleR} package.
	\item Attend at least 10 relevant research presentations per annum (student needs to verify participation by filling out and handing in the departmental attendance form for each presentation to the Statistics Department office.
		This has been completed, with the talks attended summarised in table \ref{talks}, and hard copy forms with further details available at the Statistics Department Office.
	\item Participate in the Department of Statistics PhD Talks Day and/or give a departmental seminar, to the satisfaction of the main supervisor. 
		Also, maintain a personal profile page (www.directory.auckland.ac.nz), providing information on scholarly activities and objectives to the satisfaction of the main supervisor and a Department of Statistics PhD Officer.
		This proposal will accompany a departmental seminar, and the personal profile page can be located at \url{https://directory.auckland.ac.nz/people/profile/jcai849}
	\item Attendance at one of the Faculty of Science Doctoral Induction Workshops.
		This was completed  on 2020-09-16.
\end{enumerate}

\begin{table}
	\begin{tabular}{lll}
		\toprule
		Date & Speaker & Title\\
		\midrule
		2020-06-19 & Malia Puloka & Posing Investigative Questions about Categorical Data - a Year 9 Case Study\\
		2020-07-22 & Yifu Tang & Likelihood Approximations for Time Series and Calibration of Approximate Bayesian Credible Sets\\
		2020-07-29 & Luke Boyle & Understanding Surgical Outcomes in New Zealand\\
		2020-11-12 & Andrew Holbrook & Bayes in the Time of Big Data\\
		2020-11-24 & Richard Perry & Modelling for COVID in Official Economic Time Series\\
		2020-11-25 & Rolf Turner & A Versatile Discrete Distribution\\
		2020-12-02 & Innocenter Amina & Integrative Analysis of High-Dimensional Data with Application to Soil Microbiome Data\\
		2021-02-25 & Charco Hui & Natural Language Processing in Clinical Trials\\
		2021-03-31 & Yehua Zang & Branching with Decision Detection\\
		Date & Speaker & Title\\
		\bottomrule
	\end{tabular}
	\caption{\label{talks}Talks attended as part of first year goals}
\end{table}

%Timeline
%First year goals list, incl. table of seminars attended
% Publication, conference
% Timeline
\section{Budget}

The development of the project itself, revolving around open-source software, does not come with any budgeting demands.
However, the field of research is rapidly moving, and requires conference attendance and presentations in order to maintain relevance.
This has been budgeted at \$1000.00 per annum, with the funds to be derived from the Postgraduate Research Student Support (PReSS) account, on an as-needed basis.
This is referenced in the Doctoral Provisional Year Review document, and is less than the budget cap of \$1200.00 for the statistics department

\printbibliography

\end{document}
