\documentclass[10pt,a4paper]{article}
\usepackage{doc/header}

\begin{document}

\title{A Survey of R Packages for Local Large-Scale Computing}
\author{Jason Cairns}
\year=2020 \month=3 \day=23
\maketitle{}
\tableofcontents{}

\section{Bigmemory Collection}
\label{sec:bigmemory-collection}

The bigmemory package enables the creation of "massive matrices"
through a "big.matrix" S4 class with a similar interface to
'matrix'\cite{kane13:bigmemory}. These matrices may take up gigabytes
of memory, typically larger than RAM, and have simple operations
defined that speed up their usage. A variety of extension packages are
also available that provide more functionality for big.matrices. The
massive capacity of big.matrices is given through their default memory
allocation to shared memory, rather than working memory as in most R
objects. The objects in R are therefore pointers, and the big.matrix
"show" method prints a description and memory location instead of a
standard matrix display, given that it is likely far too big a matrix
to print reasonably. Parallel processing is made use of for the
advantage of computations and subsetting of matrices. Development on
the package is still active, however it is stable enough that updates
are intermittent. Some of the main extension packages:

\begin{description}
	\item[biganalytics] Extends bigmemory with matrix summary statistics
	      such as \texttt{colmeans}, \texttt{apply}, as well as integration
	      with the biglm package\cite{emerson16}. Biganalytics is authored by
	      the same creators of the main bigmemory package.
	\item[bigtabulate] Extends bigmemory with tabulation functions and
	      \texttt{tapply}, allowing for contingency tables and
	      \texttt{summary} of big.matrix objects\parencite{kane16}.
	\item[biglasso] Extends bigmemory matrices to allow for lasso, ridge
	      and elastic-net model fitting. It can be take advantage of multicore
	      machines, with the ability to be run in parallel. Biglasso is
	      authored by Yaohui Zeng, and described in detail in
	      \textcite{zeng2017biglasso}.
	\item[bigalgebra] Provides BLAS routines for bigmemory and native R
	      matrices. Linear Algebra functionality is given through matrix
	      arithmetic methods, such as the standard \texttt{\%*\%}. The package
	      is archived on CRAN as of February 2020, only being accessible
	      through R-Forge. This is likely due to a merger with the main
	      bigmemory package (must investigate).
	\item[bigstatsr] Was originally a set of functions for complex
	      statistical analyses on big.matrices, having since implemented and
	      provided it's own ``filebacked big matrices''\cite{prive2018efficient}. The provided
	      functions include matrix operations particularly relating to
	      bioinformatics, such as PCA, sparse linear supervised models, etc.
	      Bigstatsr is described in detail in \textcite{prive2018efficient}.
\end{description}

\subsection{LAPACK, BLAS, ATLAS}
\label{sec:blas-lapack}

BLAS is a specification for a set of low-level ``building block''
linear algebra routines\cite{lawson1979basic}. Most linear algebra
libraries conform to the BLAS specifications, including the most
prominent linear algebra library, LAPACK, with it's own set of
extensions\cite{demmel1989lapack}. LAPACK has been extended in turn to
support a variety of systems, with implementations such as ScaLAPACK
being introduced to attend to distributed memory
systems\cite{choi1992scalapack}.

\section{disk.frame}
\label{sec:disk.frame}

The package description outlines disk.frame with the following:

\begin{displaycquote}{zj20}
	A disk-based data manipulation tool for working with large-than-RAM
	datasets. Aims to lower the barrier-to-entry for manipulating large
	datasets by adhering closely to popular and familiar data
	manipulation paradigms like dplyr verbs and data.table syntax.
\end{displaycquote}

disk.frame provides a disk.frame class and derivatives, which model a
data.frame. The primary functional difference is that disk.frames can
be far larger than total RAM. This is enabled through the disk.frame
objects being allocated to shared memory, rather than working memory
as in data.frames. The transparency offered by the class is well-known
to be at a very high level, with most standard manipulations of
dataframes being applicable to disk.frame objects. I have written more
on disk.frame in the document, \href{case-study-disk.frame.pdf}{A
	disk.frame Case Study}

\section{data.table}
\label{sec:data.table}

data.table is another dataframe alternative, focussing on speed
through multithreading and well-tuned database
algorithms\cite{dowle19}. The package has introduced a unique syntax
for data.table manipulation, which is also made available in
disk.frame. data.table objects are held in RAM, so big data processing
is not easily enabled, however the package allows for serialisation of
data.tables, and chunking is possible through splitting via the
\texttt{shard} function. The package is authored by Matt Dowle,
currently an employee at H2O.ai. An overview is given in
\textcite{dowle19:_introd}, with extensive benchmarking available in
\textcite{dowle19:_bench}.

\section{fst}
\label{sec:fst}

fst is a means of serialising dataframes, as an alternative to RDS
files\cite{klik19}. Serialisation takes place extremely fast, using compression to
minimise disk usage. The package speed is increased through parallel
computation. Author Mark Klik and Yann Collet, of Facebook, Inc. fst
is a dependency of disk.frame, performing some of the background
functionality.

\section{iotools}
\label{sec:iotools}

iotools is a set of tools for managing big I/O, with an emphasis on
speed and efficiency for big data through chunking\cite{urbanek20b}.
The package provides several functions for creating and manipulating
chunks directly. Authored by Simon Urbanek and Taylor Arnold.

\section{ff}
\label{sec:ff}

The package description outlines ff with the following:

\begin{displaycquote}{adler18}
	The ff package provides atomic data structures that are stored on
	disk but behave (almost) as if they were in RAM by mapping only a
	section (pagesize) into main memory (the effective main memory
	consumption per ff object). Several access optimization techniques
	such as Hyrid Index Preprocessing (as.hi, update.ff) and
	Virtualization (virtual, vt, vw) are implemented to achieve good
	performance even with large datasets.
\end{displaycquote}

The package provides a disk-based storage for most base types in R.
This also enables sharing of objects between different R processes. ff
is authored by a German-based team, and maintained by Jens
Oehlschl√§gel, the author of True Cluster. First introduced in
2008\cite{adler08:_large_r}, there have been no updates since
mid-2018.

\begin{description}
	\item[ffbase\cite{jonge20}] is an extension to ff, providing standard
	      statistical methods for ff objects. The package is still actively
	      maintained. The package has been the subject of several talks, most
	      notably the author's overview, \textcite{wijffels13}. The package is
	      currently being revised for a second version that provides generics
	      functionality for dplyr on ff objects, under the title,
	      ``ffbase2''\cite{jonge15}.
\end{description}

\printbibliography{}

\end{document}
