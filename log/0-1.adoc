(Preparing for) Getting My Hands Dirty
======================================

== Objectives ==

.Carried
* [-] Learn more on reweighted least squares as an example iterative
algorithm
** [*] Read on reweighted least squares
** [ ] Take notes
* [*] Determine if sparklyr mutate occurs locally
* [ ] Retry cluster simulation

.New
* [*] Determine means of foreach global variable detection
* [*] Determine if futures can be persisted
* [*] Consider attributes important to large-scale R platforms
	** [*] Make a comparison table
* [-] More on pbdR, with examples:
	** [*] Do they offer a specialised API, or generics
	** [*] What does it take to set up?
	** [*] Do objects persist at nodes?
	** [ ] Implement reweighted least squares
* [ ] Write on LASSO with reference to the bigmemory implementation
* [ ] Write on other algorithms: ADMM, Random Forest
* [ ] Research possible graph-based algorithms to require node communication

== Journal ==

[horizontal]
*Tuesday*::
	- Learned vim
	- Learned asciidoc
	- Learned tmux
	- Fixed makefile
*Wednesday*::
	- Finished reading 4.2 ESL
	- Completed log fixing
*Thursday*::
	- learned vimscript, started work on
	  https://github.com/jcai849/send-to-pane[plugin] to send text from vim
	  to R 
*Friday - Monday*::
	- Long Weekend 
*Tuesday*::
	- Meeting postponed for more work to be completed
	- Reading on sparklyr, future, foreach 
*Wednesday*::
	- Crawling through source code of future
	- Writing more detail on link:../doc/detail-future.tex[future]
	persistence
*Thursday*::
	- More detail on
	  link:../doc/survey-r-packages-for-distributed-large-scale-computing.tex[sparklyr]
	  arbitrary code execution
	- More detail on link:../doc/detail-foreach.tex[foreach]
	  means of global variable detection
	- Writing on attributes important to large-scale R platforms
	  link:../doc/survey-large-scale-features.tex[Feature Survey]
*Friday*::
	- Learned Docker
	- Read _Programming with BIG data in R: Scaling analytics from one to
	  thousands of nodes_ ; very worthwhile read
	- Followed the https://pbdr.org/tutorials/jsm2017/[pbdR Essentials
	  course]
	- link:../doc/detail-pbdr.tex[Wrote on pbdR in more detail]
*Monday*::
	- implement reweighted least squares using pbdR (with their workshop
	  docker image)

== Discuss ==

* The mechanism of future is very difficult to understand - no documentation
and the code is quite unclear
* Would the promises package be useful to look into? See, for example,
+
[source, R]
---- 
promises::then(future::future({ Sys.sleep(10) "Done" }))
"Something else"
----
* I should also look at other programming languages that have solved a similar
  problem. Through playing with the python server, I came into contact with
  python's asynchronous constructs such as `asyncio`. Further searching revealed
  interesting asynchronous API's such as Kotlin's coroutines (concurrent, but not
  quite parallel), and Julia's `Distributed` library, with an interesting API
  derived from MPI, and simplified. None of these are quite what we're looking
  for (Julia is the closest) but there's definitely info there on what to do and
  avoid in creating API's. cf:
  https://quentin.pradet.me/blog/using-asynchronous-for-loops-in-python.html[asynchronous
  iteration in python],
  https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Core-or-Distributed-Processing-1[Distributed
  processing with Julia]
* Docker seems quite promising to ease setup if needed. How about Kubernetes
  for cluster management? I don't know much about it but hear it referenced
  enough
