. Get multiple sessions on each host
. Writing on doc/experiment-distributed-decision-tree.tex
. Pruning for tree
. Start on mid-level MapReduce-style api for the distributed objects
. Regression in CART
. Attempt to apply GLM as per Simon's email to the distributed object
. implement some sort in eager dist obj
. Interface: experiment with lazy distributed objects
. Implementation: experiment with metadata being encapsulated in slave processes
. Notes on Hadoop Monitoring links (which port for what, etc.)
.. Create startup script that also starts up web browser with relevant
   monitoring pages
. Remove table notes from link:doc/survey-large-scale-features.tex[Large Scale
  Features document] and add them to their appropriate sections; consider how to
  do this neatly.
. Revisit table with reference to sparklyr-iteration
. Add "degree of control" to the large scale features; capturing how much is
  abstracted vs. still able to be specified by the programmer
. Read Spark: The Definitive Guide
.. 1. What Is Apache Spark?
.. 2. A Gentle Introduction to Spark
.. 3. A Tour of Spark's Toolset
.. 15. How Spark Runs on a Cluster
.. 17. Deploying Spark
.. 18. Monitoring and Debugging
.. 24. Advanced Analytics and Machine Learning Overview
.. 32.2. R on Spark
. Discuss why spark no longer has RDDs as main objects
. Look at sparkR?
. A Survey of Distributed Statistical Algorithms
. Determine feasibility of Spark making use of R blobs in a long-running R
  process: Arrow potentially capable? See how sparklyr uses it
. Record the backends commonly supported by backend-powered packages (include
  these in the survey-large-scale-platforms document, including revis and other
  distributed databases)
. Write on LASSO with reference to the bigmemory implementation
. Write on other algorithms: ADMM, Random Forest
. Research possible graph-based algorithms that require node communication
. More on RWLS document
.. Reference the GLM implementations in sparklyr and pbdR
. Notes on s-u
. Highlight useful bib entries; take notes
