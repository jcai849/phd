. run spark on the local pseudodistributed cluster
. test sparklyr table names, see if they correspond completely to R variables (can names be used in R?)
. Implement Babylonian method for sparklyr
. Copy to cluster, test
. Complete link:doc/review-sparklyr-iteration.tex[sparklyr iteration doc]
. Begin prototyping; see ROctopus as relevant experiment
. Remove table notes from link:doc/survey-large-scale-features.tex[Large Scale
  Features document] and add them to their appropriate sections; consider how to
  do this neatly.
. Read Spark: The Definitive Guide
.. 1. What Is Apache Spark?
.. 2. A Gentle Introduction to Spark
.. 3. A Tour of Spark's Toolset
.. 15. How Spark Runs on a Cluster
.. 17. Deploying Spark
.. 18. Monitoring and Debugging
.. 24. Advanced Analytics and Machine Learning Overview
.. 32.2. R on Spark
. Discuss why spark no longer has RDDs as main objects
. Record the backends commonly supported by backend-powered packages (include
  these in the survey-large-scale-platforms document, including revis and other
  distributed databases)
. Write on LASSO with reference to the bigmemory implementation
. Write on other algorithms: ADMM, Random Forest
. Research possible graph-based algorithms to require node communication
. More on RWLS document
.. Reference the GLM implementations in sparklyr and pbdR
. Write on comparative benefits and drawbacks in majore packages
