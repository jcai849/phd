. Implement some distributed algorithms
.. Implement basic statistics with current interface
... Implement `match_host_indices`
.... Implement `]`
.... Implement `send` for objects smaller than cluster
.... Implement p2p communication (overload `send`)
.. Implement a more advanced algorithm in the raw
.. Notes on implementations; add `str(dist.vec)` for demonstration
. Interface: experiment with lazy distributed objects
. Implementation: experiment with metadata being encapsulated in slave processes
. Notes on Hadoop Monitoring links (which port for what, etc.)
.. Create startup script that also starts up web browser with relevant
   monitoring pages
. Remove table notes from link:doc/survey-large-scale-features.tex[Large Scale
  Features document] and add them to their appropriate sections; consider how to
  do this neatly.
. Revisit table with reference to sparklyr-iteration
. Add "degree of control" to the large scale features; capturing how much is
  abstracted vs. still able to be specified by the programmer
. Read Spark: The Definitive Guide
.. 1. What Is Apache Spark?
.. 2. A Gentle Introduction to Spark
.. 3. A Tour of Spark's Toolset
.. 15. How Spark Runs on a Cluster
.. 17. Deploying Spark
.. 18. Monitoring and Debugging
.. 24. Advanced Analytics and Machine Learning Overview
.. 32.2. R on Spark
. Discuss why spark no longer has RDDs as main objects
. Look at sparkR?
. Determine feasibility of Spark making use of R blobs in a long-running R
  process: Arrow potentially capable? See how sparklyr uses it
. Record the backends commonly supported by backend-powered packages (include
  these in the survey-large-scale-platforms document, including revis and other
  distributed databases)
. Write on LASSO with reference to the bigmemory implementation
. Write on other algorithms: ADMM, Random Forest
. Research possible graph-based algorithms to require node communication
. More on RWLS document
.. Reference the GLM implementations in sparklyr and pbdR
. Notes on s-u
. Highlight useful bib entries; take notes
